# -*- coding: utf-8 -*-
"""
Created on Wed Aug 14 20:04:34 2019

@author: HP
"""

#A lot of effort in solving any machine learning problem goes in to preparing the data.
#PyTorch provides many tools to make data loading easy and hopefully, to make your code more
#readable. In this turtorial, we will see how to load and preprocess/argument data from a 
#non trivial dataset.

#To run this turorial,please make sure the following packages are installed:

# 1. scikit-image：For image io and transforms
# 2. pandas: For easier csv parsing

from __future__ import print_function,division
import os
import torch
import pandas as pd
from skimage import io,transform
import numpy as np
from torch.utils.data import Dataset,DataLoader
import matplotlib.pyplot as plt
from torchvision import transforms,utils

#Ignore warings
import warnings
warnings.filterwarnings("ignore")

plt.ion()

#The dataset we are going to deal with is that of facial pose. This means that a face is annotated like this

##Note
#--------------------------------------------
#Download the dataset from here so that the images are in a directory named 'data/faces/'.This dataset
#was actually generated by applying excellent dlib's pose estimation on a few images from
# imagenet tagged as 'face'
#-----------------------------------------------------------------------------------------------
#Dataset comes with a csv file with annotations which looks like this:
#image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x,

#Let's quickly read the CSV and get the annotation in an (N,2) array where N is the number of landmarks
landmarks_frame=pd.read_csv('data/faces/face_landmarks.csv')

n=65
img_name=landmarks_frame.iloc[n,0];
landmarks=landmarks_frame.iloc[n,1:].as_matrix()
landmarks=landmarks.astype('float').reshape(-1,2)

print('Image name: {}'.format(img_name))
print('landmarks shape:{}'.format(landmarks.shape))
print('First 4 landmarks:{}'.format(landmarks[:4]))

#Let's write a simple helper function to show an image and its landmarks and use it to show a sample
def show_landmarks(image,landmarks):
    """show image with landmarks"""
    plt.imshow(image)
    plt.scatter(landmarks[:,0],landmarks[:,1],s=10,marker='.',c='r')
    plt.pause(0.001)#pause a bit so that plots are updated
    
    
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/',img_name)),landmarks)
plt.show()

#Dataset class
#torch.utils.data.Dataset is an abstract class representing a dataset.Your custom dataset
#should inherit Dataset and override the following methods:

#-----------------------------------------------------------------------------------
# 1. __len__ so that len(dataset) returns the size of the dataset.
# 2. __getitem__ to support the indexing such that dataset[i] can be used to get ith sample
#----------------------------------------------------------------------------------------------

#Let's create a dataset class for our face landmarks dataset. We will read the csv in __init__ but 
#leave the reading of images to __getitem__.
#This is memory efficient because all the images are not stored in the memory at once but 
#read as required

#Sample of our dataset will be a dict{'image': image,'landmarks':landmarks}.Our dataset will take
#an optional argument transform so that any required processing can be applied on the sample.WE
#will see the usefulness of transform in the next section

class FaceLandmarksDataset(Dataset):
    """Face Landmarks dataset."""
    
    def __init__(self,csv_file,root_dir,transform=None):
        """
        Args:
            csv_file(string):Path to the csv file with annotations.
            root_dir(string):Directory with all the images.
            transform(callable,optional):optional transform to be appied
            on a sample.
        """
        self.landmarks_frame=pd.read_csv(csv_file)
        self.root_dir=root_dir
        self.transform=transform
    
    def __len__(self):
        return len(self.landmarks_frame)
    
    def __getitem__(self,idx):
        img_name=os.path.join(self.root_dir,self.landmarks_frame.iloc[idx,0])
        image=io.imread(img_name)
        landmarks=self.landmarks_frame.iloc[idx,1:]
        landmarks=np.array([landmarks])
        landmarks=landmarks.astype('float').reshape(-1,2)
        sample={'image':image,'landmarks':landmarks}
        
        if self.transform:
            sample=self.transform(sample)
            
        return sample
    
    
#Let's instantiate this class and iterate through the data samples.
#We will print the size of first 4 smaples and show their landmarks
        
face_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',
                                  root_dir='data/faces/')


fig=plt.figure()
#print('_______________________________________________')
#print(len(face_dataset))

for i in range(len(face_dataset)):
    sample=face_dataset[i]
    print(i)
    print(i,sample['image'].shape,sample['landmarks'].shape)
    
    ax=plt.subplot(1,4,i+1)
#    subplot(numRows, numCols, plotNum)
    
    plt.tight_layout()
    ax.set_title('Sample #{}'.format(i))
    ax.axis('off')
    show_landmarks(**sample)
    
    if i==3:
        plt.show()
        break



#Transforms
        
# one issue we can see from the above is that the samples are not of the samesize.
# Most neural networks expect the images of a fixed size.
# Therefore, we will need to write some prepocessing code. Let's create three transforms:
# 1.Rescale: to scale the image
# 2.RandomCrop: to crop from image randomly. This is data augmentation.
# <tip> crop:裁剪
        
#We will write them as callable classes instead of simple functions so that parameters of 
#the transform need not be passed everytime it's called.
#For this, we just neeed to implement __call__ method and if required,__init__method.We can then
#use a transfrom like this:

#       tsfm=Transform(params)
#       tranformed_sample=tsfm(sample)
        
#  Observe below how these transforms had to be applied both on the image and landmarks.

class Rescale(object):
    """Rescale the image in a sample to a given size.
    Args:
        output_size(tuple or int):Desired output size. If tuple, output is
        matched to output_size.If int ,smaller of image edges is matched to output_size
        keeping aspect ratio the same.
    """

    def __init__(self,output_size):
        assert isinstance(output_size,(int,tuple))
        self.output_size=output_size
    
    def __call__(self,sample):
        image,landmarks=sample['image'],sample['landmarks']
        
        h,w=image.shape[:2]
        if isinstance(self.output_size,int):
            if h>w:
                new_h,new_w=self.output_size*h/w,self.output_size
            else:
                new_h,new_w=self.output_size,self.output_size*w/h
                
        new_h,new_w=int(new_h),int(new_w)
        
        img=transform.resize(image,(new_h,new_w))
        
        #h and w are swapped for landmarks because for images,
        #x and y axes are axis 1 and 0 respectively
        landmarks=landmarks*[new_w/w,new_h/h]
        
        return {'image':img,'landmarks':landmarks}
    



class RandomCrop(object):
    """Crop randomly the image in sample.
    
    Args:
        output_size(tuple or int): Desired output size. If int ,square crop is made.
    """
    def __init__(self,output_size):
        assert isinstance(output_size,(int,tuple))
        if isinstance(output_size,int):
            self.output_size=(output_size,output_size)
        else:
            assert len(output_size)==2
            self.output_size=output_size
            
    def __call__(self,sample):
        image,landmarks=sample['image'],sample['landmarks']
        
        h,w=image.shape[:2]
        new_h,new_w=self.output_size
        
        top=np.random.randint(0,h-new_h)
        left=np.random.randint(0,w-new_w)
        
        image=image[top:top+new_h,
                    left:left+new_w]
        
        landmarks=landmarks-[left,top]
        
        return{'image':image,'landmarks':landmarks}
        
class ToTensor(object):
    """Convert ndarrays in sample to Tensor."""
    
    def __call__(self,sample):
        image,landmarks=sample['image'],sample['landmarks']
        
        #swap color axis because
        #numpy image:H*W*C
        #torch image:C*H*W
        image=image.transpose((2,0,1))
        return {'image':torch.from_numpy(image),
                'landmarks':torch.from_numpy(landmarks)}
        
        
        
#Compose transforms

#Now, we apply the transforms on a sample.
#Let'say we want to rescale the shorter side of the image to 256 and then randomly crop a square of 
#size 224 from it. i.e, we want to compose Rescale and RandomCrop transforms. torchvision.transform.Compose
#is a simple callable class which allows us to do this
        
scale=Rescale(256)
crop=RandomCrop(128)
composed=transforms.Compose([Rescale(256),
                             RandomCrop(224)])
            
#Apply each of the above transforms on sample.
fig=plt.figure()
sample=face_dataset[65]
for i,tsfrm in enumerate([scale,crop,composed]):
    transformed_sample=tsfrm(sample)
    
    ax=plt.subplot(1,3,i+1)
    plt.tight_layout()
    ax.set_title(type(tsfrm).__name__)
    show_landmarks(**transformed_sample)
    
plt.show()


#Iterating through the dataset

#Let's put this all together to create a dataset with composed tranforms. 
#To summarize, everytime this dataset is sampled:
# 1. An image is read from the file on the fly
# 2. Transforms are applied on the read image
# 3. since one of the transforms is random,data is augmentated on sampling

#We can iterate over the created dataset with a for i in range loop as before
transformed_dataset=FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',
                                         root_dir='data/faces/',
                                         transform=transforms.Compose([
                                                 Rescale(256),
                                                 RandomCrop(224),
                                                 ToTensor()
                                                 ]))
            
for i in range(len(transformed_dataset)):
    sample=transformed_dataset[i]
    
    print(i,sample['image'].size(),sample['landmarks'].size())
    
    if i==3:
        break
    
    
#However, we are losing a lot of features by using s simple for loop to iterate over the data.
#In particular, we are missing out on:
# 1. Batching the data
# 2. Shuffling the data
# 3. Load the data in parallel using multiprocessing workers

#torch.utils.DetaLoader is an iterator which provides all these features.parameters used below should
#be clear.One parameter of interest is collate_fn.You can specify how exactly the samples need to be
#batched using collate_fn. However, default collate should work fine for most use cases.
        

dataloader=DataLoader(transformed_dataset,batch_size=4,
                      shuffle=True,num_workers=0)

#Helper function to show a batch
def show_landmarks_batch(sample_batched):
    """show images with landmarks for a batch of samples."""
    images_batch,landmarks_batch=\
        sample_batched['image'],sample_batched['landmarks']
    print('-------------------------------------------------')
    
    print(landmarks_batch)
    
    print('-------------------------------------------------')
    batch_size=len(images_batch)
    im_size=images_batch.size(2)
    grid_border_size=2
        
    grid=utils.make_grid(images_batch)
    plt.imshow(grid.numpy().transpose((1,2,0)))
        
        
    for i in range(batch_size):
        plt.scatter(landmarks_batch[i,:,0].numpy()+i*im_size+(i+1)*grid_border_size,
                        landmarks_batch[i,:,1].numpy()+grid_border_size,
                        s=10,marker='.',c='r')
            
        plt.title('Batch from dataloader')
            
            
            
for i_batch,sample_batched in enumerate(dataloader):
    print(i_batch,sample_batched['image'].size(),
          sample_batched['landmarks'].size())
                
                
    #observe 4th batch and stop.
    if i_batch==3:
        plt.figure()
        show_landmarks_batch(sample_batched)
        plt.axis('off')
        plt.ioff()
        plt.show()
        break

#Afterword: torchvision
        
#In this turtorial, we have seen how to write and use datasets, transforms and dataloader 
#.torchvision package provides some common datasets and  transforms. You might not even have to 
#write custom classes. One of the more generic datasets available in torchvison is ImageFolder.


#where 'ants','bees'etc.are class labels.Similarly generic transforms which operate on PIL.image
#like RandomHorizontalFlip,Scale,are also available. You can use these to write a dataloader like this
        
#import torch
#from torchvision import transforms,datasets
#
#data_transform=transforms.Compose([
#        transforms.RandomSizedCrop(224),
#        transforms.RandomHorizontalFlip(),
#        transforms.ToTensor(),
#        transforms.Normalize(mean=[0.485,0.456,0.406],
#                             std=[0.229,0.224,0.225])
#        ])
#
#hymenoptera_dataset=datasets.ImageFolder(root='hymenoptera_data/train',
#                                         transform=data_transform)
#dataset_loader=torch.utils.data.DataLoader(hymenoptera_dataset,
#                                           batch_size=4,shuffle=True,
#                                           num_workers=4)
#





































































        
































    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
        







































    
    











































































































































